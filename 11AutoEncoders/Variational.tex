\input ../SlidePreamble
\input ../preamble


\begin{document}

{\Huge

  \centerline{\bf TTIC 31230, Fundamentals of Deep Learning}
  \bigskip
  \centerline{David McAllester, Winter 2019}
  \vfill
  \centerline{Latent Variable Models}
  \vfill
  \centerline{Expectation Maximization (EM)}
  \vfill
  \centerline{The Evidence Lower Bound (the ELBO)}
  \vfill
  \centerline{Variational Autoencoders (VAEs)}
  \vfill
  \vfill

\slide{Latent Variable Models}

{\color{red} $$P_\Phi(y) = \sum_z\;P_\Phi(z)P_\Phi(y|z) = E_{z \sim P_\Phi(z)}\;P_\Phi(y|z)$$}

Or

\vfill
{\color{red} $$P_\Phi(y|x) = \sum_z\;P_\Phi(z|x)P_\Phi(y|z,x) = E_{z \sim P_\Phi(z|x)}\;P_\Phi(y|z,x)$$}

\vfill
Here {\color{red} $z$} is a latent variable.

\slide{Latent Variable Models}

{\color{red} $$P_\Phi(y) = \sum_z\;P_\Phi(z)P_\Phi(y|z) = E_{z \sim P_\Phi(z)}\;P_\Phi(y|z)$$}

Here we often think of $z$ as the causal source of $y$.

\vfill
For example $z$ might be a physical scene causing image $y$.

\vfill
Or $z$ might be the intended utterance causing speech signal $y$.

\vfill
In these situations a latent variable model should more accurately represents the distribution on $y$.

\slide{Latent Variable Models}

{\color{red} $$P_\Phi(y) = \sum_z\;P_\Phi(z)P_\Phi(y|z) = E_{z \sim P_\Phi(z)}\;P_\Phi(y|z)$$}

\vfill
$P_\Phi(z)$ is called the prior.

\vfill
Given an observation of $y$ (the evidence) $P_\Phi(z|y)$ is called the posterior.

\vfill
Variational Bayesian inference involves approximating the posterior.

\anaslide{Colorization with Latent Segmentation}
\medskip
\centerline{\includegraphics[width = 5in]{../images/colorizationGreg2}}
\centerline{$x$ \hspace{4em} $\hat{y}$ \hspace{4em} $y$}
\centerline{\huge Larsson et al., 2016}

\vfill
Colorization is a natural self-supervised learning problem --- we delete the color and then try to recover it from the grey-level image.

\vfill
Can colorization be used to learn segmentation?

\vfill
Segmentation is latent --- not determined by the color label.

\anaslide{Colorization with Latent Segmentation}
\medskip
\centerline{\includegraphics[width = 5in]{../images/colorizationGreg2}}
\centerline{$x$ \hspace{4em} $\hat{y}$ \hspace{4em} $y$}
\centerline{\huge Larsson et al., 2016}

\vfill
$x$ is a grey level image.

\vfill
$y$ is a color image drawn from $\pop(y|x)$.

\vfill
$\hat{y}$ is an arbitrary color image.

\vfill
$P_\Phi(\hat{y}|x)$ is the probability that model $\Phi$ assigns to the color image $\hat{y}$ given grey level image $x$.

\anaslide{Colorization with Latent Segmentation}
\medskip
\centerline{\includegraphics[width = 5in]{../images/colorizationGreg2}}
\centerline{$x$ \hspace{4em} $\hat{y}$ \hspace{4em} $y$}

\vfill
{\color{red} $$P_\Phi(\hat{y}|x) = \sum_z\;P_\Phi(z|x)P_\Phi(\hat{y}|z,x).$$}
\begin{eqnarray*}
\mbox{input}\; x \\
P_\Phi(z|x) & = & \ldots \;\;\mbox{\color{red} semantic segmentation} \\
P_\Phi(\hat{y}|z,x) & = & \ldots \;\;\mbox{\color{red} segment colorization} \\
\end{eqnarray*}

\anaslide{Assumptions}

\bigskip
\bigskip
We assume models $P_\Phi(z)$ and $P_\Phi(y|z)$ are both samplable and computable.

\vfill
In other words, we can sample from these distributions and for any given $z$ and $y$ we can compute $P_\Phi(z)$ and $P_\Phi(y|z)$.

\vfill
These are nontrivial assumptions.

\vfill
A loopy graphical model is neither (efficiently) samplable nor computable.

\slide{Cases Where the Assumptions Hold}

In CTC we have that $z$ is the sequence with blanks and $y$ is the result of removing the blanks from $z$.

\vfill
In a hidden markov model $z$ is the sequence of hidden states and $y$ is the sequence of emissions.

\vfill
An autoregressive model, such as an autoregressive language model, is both samplable and computable.

\slide{Image Generators}

\centerline{$z$ \includegraphics[width=4in]{\images/deconvright}$y$}

\vfill
We can generate an image $y$ from noise $z$ where $p_\Phi(z)$ and $p_\Phi(y|z)$ are both samplable and computable.

\slide{Image Generators}

\centerline{$z$ \includegraphics[width=4in]{\images/deconvright}$y$}

\vfill
Typically $p_\Phi(z)$ is ${\cal N}(0,I)$ reshaped as $z[X,Y,J]$

\vfill
We can generate an image $y$ form noise $z$ where $p_\Phi(z)$ and $p_\Phi(y|z)$ are both samplable and computable.

\anaslide{Assumptions}

\bigskip
\bigskip
We assume models $P_\Phi(z)$ and $P_\Phi(y|z)$ are both samplable and computable.

\vfill
When the assumptions hold we can sample from $P_\Phi(y)$ but we cannot typically compute $P_\Phi(y)$.

\vfill
In particular, for an image generator we cannot compute $P_\Phi(y)$.

\vfill
Hence it is not obvious how to optimize the fundamental equation.

$$\Phi^* = \argmin_\Phi\;E_{y \sim \pop}\;- \ln P_\Phi(y)$$

\slide{Shifting the Difficulty}

For any $z$ we have

\vfill
\begin{eqnarray*}
P_\Phi(y) & = & \frac{P_\Phi(y)P_\Phi(z|y)}{P_\Phi(z|y)} \\
\\
\\
& = & \frac{P_\Phi(z) P_\Phi(y|z)}{P_\Phi(z|y)}
\end{eqnarray*}

\vfill
The difficulty has now been shifted to estimating $P_\Phi(z|y)$ which remains intractable but is intuitively easier than estimating $P_\Phi(y)$.

\slide{The Evidence Lower Bound (The ELBO)}

We introduce a samplable and computable model $Q_\Phi(z|y)$ to approximate $P_\Phi(z|y)$.

{\huge
\begin{eqnarray*}
 {\color{red} \ln P_\Phi(y)} & = & E_{z \sim Q_\Phi(z|y)} \ln \frac{P_\Phi(z)P_\Phi(y|z)}{P_\Phi(z|y)} \\
        \\
 & = & E_{z \sim Q_\Phi(z|y)} \left(\ln \frac{P_\Phi(z)P_\Phi(y|z)}{Q_\Phi(z|y)} + \ln \frac{Q_\Phi(z|y)}{P_\Phi(z|y)}\right) \\
 \\
  & = & \left(E_{z \sim Q_\Phi(z|y)} \ln \frac{P_\Phi(z)P_\Phi(y|z)}{Q_\Phi(z|y)}\right) + KL(Q_\Phi(z|y),P_\Phi(z|y)) \\
  \\
  & {\color{red} \geq} & {\color{red} E_{z \sim Q_\Phi(z|y)} \ln \frac{P_\Phi(z)P_\Phi(y|z)}{Q_\Phi(z|y)}}\;\;\mbox{The ELBO}
\end{eqnarray*}
}

\slide{The Variational Autoencoder (VAE)}

$$\Phi^* = \argmin_\Phi E_{y\sim \pop,\;z \sim Q_\Phi(z|y)}\;\;\ln \frac{Q_\Phi(z|y)}{P_\Phi(z,y)}$$

\slide{VAE generalizes EM}

VAE:

$$\Phi^* = \argmin_\Phi E_{y\sim \mathrm{Train},\;z \sim Q_\Phi(z|y)}\;\;\ln \frac{Q_\Phi(z|y)}{P_\Phi(z,y)}$$

\vfill
EM:  Alternately optimize $Q$ then $P$.

$$\Phi^{\color{red} t+1} =  \argmin_\Phi\;E_{y \sim \mathrm{Train}}\;E_{z \sim P_{\Phi^{\color{red} t}}(z|y)}\; - \ln P_\Phi(z,y)$$
\centerline{\hspace{1em} Update \hspace{6em} Inference \hspace{2.5em}~}
\centerline{(M Step) \hspace{5em} (E Step) \hspace{1.5em}~}
\centerline{Hold $Q$ fixed \hspace{4em} $Q^* = P_{\Phi^{\color{red} t}}$ \hspace{1.5em}~}

\slide{Hard VAEs}
\vfill
In hard EM we use $\argmax_z P_{\Phi^t}(z|y)$ rather than $E_{z \sim P_{\Phi^t}(z|y)}$.

\vfill
$K$-means is hard EM for mixtures of Gaussians (when all covariances matrices are fixed at $I$).

\vfill
By analogy with hard EM we can formulate a notion of a hard VAE.

\slide{Hard VAEs}

(Soft) VAE:
\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi E_{y,\epsilon}\;\;\ln \frac{Q_\Phi(z|y)}{P_\Phi(z,y)} \\
\\
& = & \argmin_\Phi \left(E_{z\sim Q_\Phi(z|y)} \;-\ln P_\Phi(z,y)\right) - H(Q_\Phi(z|y))
\end{eqnarray*}

\vfill
Hard VAE:
$$\Phi^* = \argmin_\Phi E_{z\sim Q_\Phi(z|y)} \;-\ln P_\Phi(z,y)$$

\vfill
For a hard VAE we have that $Q^*$ focuses on a single value.  Even for a soft VAE $Q$ can suffer from mode collapse.

\slide{The Reparameterization Trick}

\begin{eqnarray*}
- \ln P_\Phi(y) & \leq & E_{z \sim Q_\Phi(z|y)}\;\ln \frac{Q_\Phi(z|y)}{P_\Phi(z)P_\Phi(y|z)} \\
\\
\\
& = & E_\epsilon\;\ln \frac{Q_\Phi(z|y)}{P_\Phi(z)P_\Phi(y|z)}\;\;\;z := f_\Phi(y,\epsilon)
\end{eqnarray*}

\vfill
$\epsilon$ is parameter-independent noise.

\vfill
This supports SGD: $\nabla_\Phi \;E_{y,\epsilon}\; [\ldots] = E_{y,\epsilon}\; \nabla_\Phi\;[\ldots]$

\slide{Posterior Collapse}

Assume Universal Expressiveness for $P_\Phi(y|z)$.

\vfill
This allows $P_\Phi(y|z) = \pop(y)$ independent of $z$.

\vfill
We then get a completely optimized model with $z$ taking a single (meaningless) determined value.

\vfill
$$Q_\Phi(z|y) = P_\Phi(z|y) = 1$$

\anaslide{Colorization with Latent Segmentation}
\medskip
\centerline{\includegraphics[width = 5in]{../images/colorizationGreg2}}
\centerline{$x$ \hspace{4em} $\hat{y}$ \hspace{4em} $y$}
\centerline{\huge Larsson et al., 2016}

\vfill
Can colorization be used to learn latent segmentation?

\vfill
We introduce a latent segmentation into the model.

\vfill
In practice the latent segmentation is likely to ``collapse'' because the colorization can be done just as well without it.


\slide{Optimizing the VAE leaves $I(y,z)$ undetermined}

\vfill
Complete optimization gives $P_\Phi(y) = \pop(y)$.  But this does not determine $Q_\Phi(z|y)$.

\vfill
At complete optimization the value of the objective function is $H(y)$.  But we have

\vfill
$$H(y) = I(y,z) +       H(y|z)$$

\vfill
The VAE operates on the joint distribution on $y$ and $z$ determined by $\pop(y)$ and $Q_\Phi(z|y)$.

\vfill
Posterior collapse is the case of $I(y,z) = 0$.

\slide{The $\beta$-VAE}

$\beta$-VAE: Learning Basic Visual Concepts With A
Constrained Variational Framework, Higgins et al., ICLR 2017.

\vfill
The VAE:

$$\Phi^* = \argmin_\Phi E_{y,\epsilon}\;\ln \frac{Q_\Phi(z|y)}{P_\Phi(z)P_\Phi(y|z)}$$

\vfill
The $\beta$-VAE:

$$\Phi^* = \argmin_\Phi E_{y,\epsilon}\;\;\;\beta \ln \frac{Q_\Phi(z|y)}{P_\Phi(z)} - \ln P_\Phi(y|z)$$

\slide{The $\beta$-VAE}

$\beta$-VAE: Learning Basic Visual Concepts With A
Constrained Variational Framework, Higgins et al., ICLR 2017.

\vfill
The $\beta$-VAE:

$$\Phi^* = \argmin_\Phi E_{y,\epsilon}\;\;\;\beta \ln \frac{Q_\Phi(z|y)}{P_\Phi(z)} - \ln P_\Phi(y|z)$$

\vfill
The paper claims that taking $\beta > 1$ can prevent posterior collapse. More Later.


\slide{Noisy-Channel RDAs vs. $\beta$-VAEs}

Noisy-Channel RDA
\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi E_{y,\epsilon}\;\ln \frac{p_\Phi(z|y)}{q_\Phi(z)} + \lambda \mathrm{Dist}(y,y_\Phi(z))\;\;z := f_\Phi(y,\epsilon)
\end{eqnarray*}


\vfill
$\beta$-VAE
\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi E_{y,\epsilon}\;\;\;\beta \ln \frac{q_\Phi(z|y)}{p_\Phi(z)} - \ln p_\Phi(y|z)\;\;\;z := f_\Phi(y,\epsilon)
\end{eqnarray*}


\slide{$L_2$ Distortion and Gaussian Image Noise}

Using $L_2$ distortion and $p_\Phi(y|z) \propto \exp(-||y - y_\Phi(z)||/(2\sigma^2))$

\vfill
Noisy-Channel RDA
\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi E_{y,\epsilon}\;\ln \frac{p_\Phi(z|y)}{q_\Phi(z)} + \lambda ||y - y_\Phi(z)||^2
\end{eqnarray*}

\vfill
$\beta$-VAE
\begin{eqnarray*}
\Phi^* & = & \argmin_{\Phi,\sigma} E_{y,\epsilon}\;\;\;\beta \ln \frac{q_\Phi(z|y)}{p_\Phi(z)} +\left(\frac{1}{2\sigma^2}\right)||y - y_\Phi(z)||^2 + \ln \sigma
\end{eqnarray*}

\slide{Gaussian Image Noise}

for $p_\Phi(y|z) \propto \exp(-||y - y_\Phi(z)||/(2\sigma^2))$ we have

\vfill
$\beta$-VAE
\begin{eqnarray*}
\Phi^* & = & \argmin_{\Phi,\sigma} E_{y,\epsilon}\;\;\;\beta \ln \frac{q_\Phi(z|y)}{p_\Phi(z)} +\left(\frac{1}{2\sigma^2}\right)||y - y_\Phi(z)||^2 + \ln \sigma \\
\\
\\
\mbox{where}\;\;\sigma^* & = & \sqrt{E_{y,\epsilon}\; ||y - y_\Phi(z)||^2}
\end{eqnarray*}


\slide{Partial Optimization}

Noisy-Channel RDA
\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi E_{y,\epsilon}\;\ln \frac{p_\Phi(z|y)}{q_\Phi(z)} + \lambda \mathrm{Dist}(y, y_\Phi(z)) \\
\\
q^*(z) & = & p_{\mathrm{pop}}(z) \;=\;E_{y \sim \mathrm{pop}}\;p_\Phi(z|y)
\end{eqnarray*}

\vfill
$\beta$-VAE
\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi E_{y,\epsilon}\;\;\;\beta \ln \frac{q_\Phi(z|y)}{p_\Phi(z)} - \ln p_\Phi(y|z) \\
\\
p^*(z) & = & p_{\mathrm{pop}}(z) \;=\; E_{y \sim \mathrm{pop}}\;q_\Phi(z|y)
\end{eqnarray*}

\slide{Inserting the Optima}

Noisy-Channel RDA

\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi \;\;\; I(y,z) + \lambda E_{y,\epsilon}\; \mathrm{Dist}(y, y_\Phi(z))
\end{eqnarray*}

\vfill
$\beta$-VAE
\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi \;\;\; \beta I(y,z) - E_{y,\epsilon}\;\ln p_\Phi(y|z)
\end{eqnarray*}

\vfill
where the joint distribution on $y$ and $z$ is determined by $\mathrm{pop}(y)$ and the respective encoder distributions.

\slide{Semantics of the $\beta$-VAE seems unclear}

\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi \;\;\;\;\beta I(y,z) -  E_{y,\epsilon}\;\ln p_\Phi(y|z) \\
\\
& = & \beta I(y,z) + H(y|z)
\end{eqnarray*}

\vfill
We are minimizing the mutual information term.  To encourage large mutual information we should take $\beta < 1$ not $\beta > 1$ as recommended.

\slide{A VAE for Images}

Auto-Encoding Variational Bayes, Diederik P Kingma, Max Welling, 2013.

\vfill
$${\color{red}y \hspace{5em}  z_\Psi(y,\epsilon) \hspace{4em} z\;p_\Phi(z) \hspace{3em} \hat{y}_\Phi(z) \hspace{3em}||y - \hat{y}||^2}$$
\centerline{\includegraphics[width=9in]{../images/Deconv}}

\centerline{\Large [Hyeonwoo Noh et al.]}


\slide{Gaussian VAEs} 
$$\Phi^* = \argmin_\Phi E_{y,\epsilon}\;\ln \frac{p_\Phi(\tilde{z}|y)}{q_\Phi(\tilde{z})} + \lambda \mathrm{Dist}(y,y_\Phi(\tilde{z}))$$

{\color{red}
\begin{eqnarray*}
\tilde{z}[i] & = & z_\Phi(y)[i] + \sigma_\Phi(y)\epsilon[i]\;\;\;\epsilon[i] \sim {\cal N}(0,1) \\
\\
p_\Phi(\tilde{z}[i]|y) & = & {\cal N}(z_\Phi(y)[i],\sigma_\Phi(y)[i]) \\
\\
q_\Phi(\tilde{z}[i]) & = & {\cal N}(\mu_q[i],\sigma_q[i]) \;\;\mbox{WLOG} = {\cal N}(0,1) \\
\\
p_\Phi(y[i]|z) & = & {\cal N}(y_\Phi(z)[i],\;\sigma_\Phi(z)[i])
\end{eqnarray*}
}

\slide{Sampling}

\centerline{Sample {\color{red} $z \sim {\cal N}(0,I)$} and compute {\color{red} $y_\Phi(z)$}}

\vfill
\centerline{\includegraphics[width = 4in]{../images/VariationalFaces}}
\centerline{[Alec Radford]}

\slide{Vector Quantized VAEs (VQ-VAE)}

Neural Discrete Representation Learning, van den Ord et al., ArXiv 1711.00937, Neurips 2017.

\vfill
Generating Diverse High-Fidelity Images
with VQ-VAE-2, Razavi et al, arXiv 1906.00446

\vfill
VQ-VAEs effectively perform $k$-means on vectors in the model so as to represent vectors by discrete cluster centers.

\slide{Vector Quantized VAEs (VQ-VAE)}

\vfill
For concreteness we will consider VQ-VAEs on images with a single layer of quantization.

\vfill
We will use $s$ (for signal) to denote images.

\slide{VQ-VAE Encoder-Decoder}

We train a dictionary $C[K,I]$ where $C[k,I]$ is the center vector of cluster $k$.

\vfill
\begin{eqnarray*}
L[X,Y,I] & = & \mathrm{Enc}_\Phi(s) \\
\\
k[x,y] & = & \argmin_k \;||L[x,y,I] - C[k,I]|| \\
\\
\hat{L}[x,y,I] & = & C[k[x,y],I] \\
\\
\hat{s} & = & \mathrm{Dec}_\Phi(\hat{L}[X,Y,I])
\end{eqnarray*}

\slide{VQ-VAE Training Loss}

We will interpret the VQ-VAE as a noisy-channel RDA.

$$\Phi^*  =  \argmin_\Phi E_s\;I(s,k) + \lambda\mathrm{Dist}(s,\hat{s})$$

\vfill
The mutual information $I(s,k)$ is limited by the entropy of $k[X,Y]$ which can be no larger than $\ln K^{XY} = XY\ln K$.

\vfill
Maximizing $I(s,k)$ subject to this upper bound should reduce the distortion by providing the decoder with adequate information
about the image.

\slide{VQ-VAE Training Loss}

We preserve information about the image $s$ by minimizing the distortion between $L[X,Y,I]$ and its reconstruction $\hat{L}[X,Y,I]$.

\vfill
\begin{eqnarray*}
\Phi^* & = & \argmin_\Phi \;E_s\; \sum_{x,y} ||L[x,y,I] - \hat{L}[x,y,I]||^2 + \lambda \mathrm{Dist}(s,\hat{s})
\end{eqnarray*}

\vfill
This is a two-level rate-distortion auto-encoder where the rate is ultimately governed by the size $K$ of the codebook $C[K,I]$.

\slide{VQ-VAE Training Loss}

Unfortunately the latent variable $k[X,Y]$ is discrete and has no gradient.  Hence some approximation must be used.  They use:

\begin{eqnarray*}
L[x,y,I].\grad & = & \hat{L}[x,y,I].\grad \\
\\
C[k,I].\grad & = & \beta \sum_{x,y: k[x,y] = k}\;(C[k,I] - L[x,y,I])
\end{eqnarray*}

\slide{VQ-VAE Training Loss}

\begin{eqnarray*}
L[x,y,I].\grad & = & \hat{L}[x,y,I].\grad \\
\\
C[k,I].\grad & = & \beta \sum_{x,y: k[x,y] = k}\;(C[k,I] - L[x,y,I])
\end{eqnarray*}

\vfill
The first equation is the ``straight through'' gradient.  This makes sense for low distortion between $L[X,Y,I]$ and $\hat{L}[X,Y,I]$.

\vfill
If the second gradient is zero then $C[k,I]$ is the mean of the vectors assigned to $k$.  Then $C[K,I]$ is a minimizer of the distortion
between $L(X,Y,I)$ and $\hat{L}(X,Y,I)$.

\slide{Training Phase II}

Once the model is trained we can sample images $s$ and compute the ``symbolic image'' $k[X,Y]$.

\vfill
Given samples of symbolic images $k[X,Y]$ we can learn an auto-regressive model of these symbolic images using a pixalCNN.

\vfill
This yields a prior probability distribution $P_\Phi(k[X,Y])$ which provides a tighter upper bound on the rate.

\vfill
We can then measure compression and distortion for test images.  This is something GANs cannot do.

\slide{Multi-Layer Vector Quantized VAEs}
\centerline{\includegraphics[width =10in]{\images/VQ-VAE24}}

\slide{VAEs in 2019}

\centerline{\includegraphics[width = 8in]{\images/VQ-VAE22}}

\vfill
VQ-VAE-2, Razavi et al. June, 2019

\slide{VAEs in 2019}

\centerline{\includegraphics[width = 10in]{/users/davidmcallester/tex/images/VQ-VAE21}}

\vfill
VQ-VAE-2, Razavi et al. June, 2019

\slide{Quantitative Evaluation}

The VQ-VAE2 paper reports a classification accuracy score (CAS) for class-conditional image generation.

\vfill
We generate image-class pairs from the generative model trained on the ImageNet training data.

\vfill
We then train an image classifier from the generated pairs and measure its accuracy on the ImageNet test set.

\vfill
\centerline{\includegraphics[width=7in]{\images/VQ-VAE23}}

\slide{Direct Rate-Distortion Evaluation.}

Rate-distortion metrics for image compression to discrete representations support unambiguous rate-distortion evaluation.

\vfill
Rate-distortion metrics also allow one to explore the rate-distortion trade-off.

\vfill
\centerline{\includegraphics[width = 10in]{\images/VQVAE2Scores}}

\slide{Vector Quantization (Emergent Symbols)}

Vector quantization represents a distribution (or density) on vectors with a discrete set of embedded symbols.

\vfill
Vector quantization optimizes a rate-distortion tradeoff for vector compression.

\vfill
The VQ-VAE uses vector quantization to construct a discrete representation of images and hence a measurable image compression rate-distortion trade-off.

\slide{Symbols: A Better Learning Bias}

Do the objects of reality fall into categories?

\vfill
If so, shouldn't a learning architecture be designed to categorize?

\vfill
Whole image symbols would yield emergent whole image classification.

\slide{Symbols: Improved Interpretability}

Vector quantization shifts interpretation from linear threshold units to the emergent symbols.

\vfill
This seems related to the use of t-SNE as a tool in interpretation.


\slide{Symbols: Unifying Vision and Language}

Modern language models use word vectors.

\vfill
Word vectors are embedded symbols.

\vfill
Vector quantization also results in models based on embedded symbols.

\slide{Symbols: Addressing the ``Forgetting'' Problem}
When we learn to ski we do not forget how to ride a bicycle.

\vfill
However, when a model is trained on a first task, retraining on a second tasks degrades performance on the first (the model ``forgets'').

\vfill
But embedded symbols can be task specific.

\vfill
The embedding of a task-specific symbol will not change when training on a different task.


\slide{Symbols: Improved Transfer Learning.}

Embedded symbols can be domain specific.

\vfill
Separating domain-general parameters from domain-specific parameters may improve transfer between domains.



\slide{Final Thought: Attention and Latent Variables}

In machine translation attention is used to handle a latent alignment between the input sentence and the gold label translation.

\vfill
In general, attention can be viewed as defining a probability distribution over a latent choice.

\vfill
The precise relationship between attention and latent variables is unclear.

\slide{END}

\end{document}
